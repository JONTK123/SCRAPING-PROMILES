# âœˆï¸ SCRAPING-PROMILES

API FastAPI para scraping de preÃ§os de passagens aÃ©reas (em reais e milhas) das principais companhias aÃ©reas brasileiras.

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa uma API RESTful usando FastAPI para realizar scraping de informaÃ§Ãµes de preÃ§os de passagens das seguintes companhias aÃ©reas:

- **LATAM** (https://www.latamairlines.com/br/pt) - Programa LATAM Pass
- **GOL** (https://www.voegol.com.br/nh/) - Programa Smiles
- **AZUL** (https://www.voeazul.com.br/home/br/pt/home) - Programa TudoAzul

## ğŸ¯ Objetivos

- Extrair preÃ§os em **reais (R$)**
- Extrair preÃ§os em **milhas/pontos**
- Implementar **dois mÃ©todos de scraping**:
  1. **Library-based**: Usando BeautifulSoup4 para parsing HTML
  2. **Regex-based**: Usando expressÃµes regulares manuais

## ğŸ“ Estrutura do Projeto

```
SCRAPING-PROMILES/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # AplicaÃ§Ã£o FastAPI principal
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ flight.py        # Modelos Pydantic
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_scraper.py  # Classe base abstrata
â”‚   â”‚   â”œâ”€â”€ latam_scraper.py # Scraper LATAM
â”‚   â”‚   â”œâ”€â”€ gol_scraper.py   # Scraper GOL
â”‚   â”‚   â””â”€â”€ azul_scraper.py  # Scraper AZUL
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ scrape.py        # Rotas da API
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ Como Usar

### InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/JONTK123/SCRAPING-PROMILES.git
cd SCRAPING-PROMILES
```

2. Crie um ambiente virtual:
```bash
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

### Executar a API

```bash
# MÃ©todo 1: Usando uvicorn diretamente
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# MÃ©todo 2: Usando Python
python -m app.main
```

A API estarÃ¡ disponÃ­vel em: http://localhost:8000

## ğŸ“š DocumentaÃ§Ã£o da API

ApÃ³s iniciar o servidor, acesse:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI Schema**: http://localhost:8000/openapi.json

## ğŸ”Œ Endpoints

### 1. Root
```http
GET /
```
Retorna informaÃ§Ãµes sobre a API.

### 2. Health Check
```http
GET /health
```
Verifica se a API estÃ¡ funcionando.

### 3. Listar Companhias AÃ©reas
```http
GET /scrape/airlines
```
Lista todas as companhias aÃ©reas suportadas.

### 4. Scrape de uma Companhia
```http
POST /scrape/flight
Content-Type: application/json

{
  "airline": "latam",
  "method": "library",
  "origin": "GRU",
  "destination": "RIO",
  "departure_date": "2024-12-01"
}
```

**ParÃ¢metros:**
- `airline`: "latam", "gol", ou "azul"
- `method`: "library" (BeautifulSoup) ou "regex" (expressÃµes regulares)
- `origin`: (Opcional) CÃ³digo do aeroporto de origem
- `destination`: (Opcional) CÃ³digo do aeroporto de destino
- `departure_date`: (Opcional) Data de partida

**Resposta:**
```json
{
  "airline": "LATAM",
  "origin": "GRU",
  "destination": "RIO",
  "departure_date": "2024-12-01",
  "price_reais": 450.00,
  "price_miles": 15000,
  "scrape_method": "library",
  "scraped_at": "2024-10-27T11:16:51.986Z",
  "url": "https://www.latamairlines.com/br/pt",
  "status": "success",
  "error_message": null
}
```

### 5. Scrape de Todas as Companhias
```http
GET /scrape/all?method=library
```

Faz scraping de todas as companhias aÃ©reas de uma vez.

**ParÃ¢metros:**
- `method`: "library" ou "regex" (padrÃ£o: "library")

## ğŸ› ï¸ Tecnologias Utilizadas

- **FastAPI** (0.104.1) - Framework web moderno e rÃ¡pido
- **Uvicorn** (0.24.0) - Servidor ASGI
- **httpx** (0.25.1) - Cliente HTTP assÃ­ncrono
- **BeautifulSoup4** (4.12.2) - Parser HTML/XML
- **lxml** (4.9.3) - Parser XML/HTML rÃ¡pido
- **Pydantic** (2.5.0) - ValidaÃ§Ã£o de dados

## ğŸ” MÃ©todos de Scraping

### 1. Library-based (BeautifulSoup)
Usa BeautifulSoup4 para fazer parsing do HTML e extrair informaÃ§Ãµes de forma estruturada:
- Busca elementos HTML por classes e tags
- Navega na Ã¡rvore DOM
- Extrai texto de elementos especÃ­ficos

### 2. Regex-based (ExpressÃµes Regulares)
Usa padrÃµes regex para extrair informaÃ§Ãµes diretamente do HTML bruto:
- PadrÃµes para preÃ§os em reais: `R$ 1.234,56`, `BRL 1234.56`
- PadrÃµes para milhas: `15.000 milhas`, `pontos: 20000`
- Mais rÃ¡pido mas menos robusto

## âš ï¸ ConsideraÃ§Ãµes

- Este projeto Ã© para fins educacionais e demonstraÃ§Ã£o
- O scraping deve respeitar os termos de uso dos sites
- Os sites podem ter proteÃ§Ãµes contra scraping (CAPTCHA, rate limiting)
- A estrutura HTML dos sites pode mudar, quebrando os scrapers
- Recomenda-se usar APIs oficiais quando disponÃ­veis

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:
- Reportar bugs
- Sugerir novas funcionalidades
- Melhorar a documentaÃ§Ã£o
- Adicionar novos scrapers

## ğŸ“„ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto e estÃ¡ disponÃ­vel sob a licenÃ§a MIT.

## ğŸ‘¤ Autor

JONTK123

---

**Nota**: Este projeto realiza scraping de dados pÃºblicos disponÃ­veis nos sites das companhias aÃ©reas. Certifique-se de respeitar os termos de uso de cada site ao usar esta API.
